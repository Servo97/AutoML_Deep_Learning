{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from math import cos, pi\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import read_preprocess\n",
    "from models import DNN, dataset_csv\n",
    "\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"tshark -r /home/user/Sarvesh/Baap_Product/AutoML_DL/security/ISCX_Botnet-Training.pcap -T fields -e ip.src -e frame.len -e     ip.proto -E separator=, -E occurrence=f > /home/user/Sarvesh/Baap_Product/AutoML_DL/security/ISCX_Botnet-Training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('./CICIDS2017/combined_data_train.csv', index_col=False)\n",
    "frame['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Label'\n",
    "y = frame[target]\n",
    "X = frame.loc[:, frame.columns != target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X_train)\n",
    "\n",
    "pca = PCA().fit(X_std)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlim(0,40,1)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_transformer = PCA(n_components=35)\n",
    "pca = pca_transformer.fit_transform(X_std)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=5, n_jobs=-1,random_state=0)\n",
    "clf.fit(pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: x: (1809840, 78), y: (1809840, 8)                \n",
      " Validation Dataset: x: (452460, 78), y: (452460, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cumulative explained variance')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = './CICIDS2017/combined_data_train.csv'\n",
    "target = 'Label'\n",
    "split = 0.2\n",
    "x_train, x_val, y_train, y_val, tgt_type = read_preprocess.read_and_preprocess(file_path, target, split)\n",
    "\n",
    "pca = PCA().fit(x_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlim(0,40,1)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_transformer = PCA(n_components=35)\n",
    "pca = pca_transformer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(pca).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).long())\n",
    "\n",
    "pca_val = pca_transformer.transform(x_val)\n",
    "x_val = torch.from_numpy(pca_val).float()\n",
    "y_val = torch.squeeze(torch.from_numpy(y_val.to_numpy()).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_lr(lr, epoch, step_size):\n",
    "    lr = lr/2 * (cos(pi*(epoch%step_size)/step_size)+1)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr, batch_size, epochs, x_train, y_train, x_val, y_val,step_size, tgt_type):\n",
    "    print(y_train.shape[1])\n",
    "    highest_acc = 0\n",
    "    net = DNN(x_train.shape[1], tgt_type, [128,128,64,32],y_train.shape[1])\n",
    "    \n",
    "    if tgt_type==\"regression\":\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        criterion = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    params = {\n",
    "        'batch_size': 64,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "    }\n",
    "    training_set = dataset_csv(x_train, y_train)\n",
    "    train_loader = DataLoader(training_set, **params)\n",
    "    validation_set = dataset_csv(x_val, y_val)\n",
    "    val_loader = DataLoader(validation_set, **params)\n",
    "    \n",
    "    \n",
    "    net = net.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for a in optimizer.param_groups:\n",
    "            lr = cosine_lr(lr, epoch, step_size) + 1e-5\n",
    "            a['lr'] = lr\n",
    "        t_loss, a, acc = 0, 0, 0\n",
    "        log = {'y_train': [], 'y_val': [], 'y_pred': [], 'y_val_pred': []}\n",
    "        for x_train, y_train in train_loader:\n",
    "            a+=1\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            net.train()\n",
    "            y_pred = net(x_train)\n",
    "            train_loss = criterion(y_pred, torch.max(y_train, 1)[1])\n",
    "            t_loss += train_loss\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            acc += (y_pred.argmax(dim=1) == torch.max(y_train, 1)[1]).sum().float() / float(y_train.size(0))\n",
    "        print(acc/a)\n",
    "        t_loss /= a\n",
    "        if epoch%1 == 0:\n",
    "            with torch.set_grad_enabled(False):\n",
    "                test_loss, a, acc = 0, 0, 0\n",
    "                for x_val, y_val in val_loader:\n",
    "                    a += 1\n",
    "                    x_val, y_val = x_val.to(device),y_val.to(device)\n",
    "                    y_test_pred = net(x_val)\n",
    "                    y_test_pred = torch.squeeze(y_test_pred)\n",
    "                    test_loss += criterion(y_test_pred, torch.max(y_val, 1)[1])\n",
    "                    acc += (y_test_pred.argmax(dim=1) == torch.max(y_val, 1)[1]).sum().float() / float(y_val.size(0))\n",
    "            if (acc/a)>highest_acc: \n",
    "                highest_acc = acc/a\n",
    "                torch.save(net.state_dict(),\"./model_info/14_may_1.pth\")\n",
    "            print(acc/a)\n",
    "            test_loss /= a\n",
    "            print(f'[epoch]: {epoch}, [Train Loss]: {t_loss.item()}, [Val Loss]: {test_loss.item()}')\n",
    "        \n",
    "        if tgt_type==\"regression\":\n",
    "            if epoch%30==0:\n",
    "                scaler_t = pickle.load(open('./model_info/scaler_t.pkl','rb'))\n",
    "                y_0 = scaler_t.inverse_transform(log['y_train'])\n",
    "                y_1 = scaler_t.inverse_transform(log['y_pred'])\n",
    "                rmse = np.sqrt(mean_squared_error(y_0,y_1))\n",
    "                print(rmse)\n",
    "                y_0 = scaler_t.inverse_transform(log['y_val'])\n",
    "                y_1 = scaler_t.inverse_transform(log['y_val_pred'])\n",
    "                rmse = np.sqrt(mean_squared_error(y_0,y_1))\n",
    "                print(rmse)\n",
    "    return net, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "tensor(0.9486, device='cuda:0')\n",
      "tensor(0.9558, device='cuda:0')\n",
      "[epoch]: 0, [Train Loss]: 0.15064316987991333, [Val Loss]: 0.1431724578142166\n",
      "tensor(0.9427, device='cuda:0')\n",
      "tensor(0.9144, device='cuda:0')\n",
      "[epoch]: 1, [Train Loss]: 0.16550908982753754, [Val Loss]: 0.2025207132101059\n",
      "tensor(0.9404, device='cuda:0')\n",
      "tensor(0.9447, device='cuda:0')\n",
      "[epoch]: 2, [Train Loss]: 0.1815788298845291, [Val Loss]: 0.17326107621192932\n",
      "tensor(0.9440, device='cuda:0')\n",
      "tensor(0.9454, device='cuda:0')\n",
      "[epoch]: 3, [Train Loss]: 0.16274936497211456, [Val Loss]: 0.1561865210533142\n",
      "tensor(0.9551, device='cuda:0')\n",
      "tensor(0.9588, device='cuda:0')\n",
      "[epoch]: 4, [Train Loss]: 0.13314948976039886, [Val Loss]: 0.117013119161129\n",
      "tensor(0.9622, device='cuda:0')\n",
      "tensor(0.9677, device='cuda:0')\n",
      "[epoch]: 5, [Train Loss]: 0.11140016466379166, [Val Loss]: 0.09680399298667908\n",
      "tensor(0.9685, device='cuda:0')\n",
      "tensor(0.9711, device='cuda:0')\n",
      "[epoch]: 6, [Train Loss]: 0.09385165572166443, [Val Loss]: 0.08940961211919785\n",
      "tensor(0.9740, device='cuda:0')\n",
      "tensor(0.9748, device='cuda:0')\n",
      "[epoch]: 7, [Train Loss]: 0.07656798511743546, [Val Loss]: 0.07660000771284103\n",
      "tensor(0.9773, device='cuda:0')\n",
      "tensor(0.9774, device='cuda:0')\n",
      "[epoch]: 8, [Train Loss]: 0.07101260125637054, [Val Loss]: 0.07179117947816849\n",
      "tensor(0.9776, device='cuda:0')\n",
      "tensor(0.9775, device='cuda:0')\n",
      "[epoch]: 9, [Train Loss]: 0.07015977799892426, [Val Loss]: 0.07148585468530655\n",
      "tensor(0.9777, device='cuda:0')\n",
      "tensor(0.9776, device='cuda:0')\n",
      "[epoch]: 10, [Train Loss]: 0.06962345540523529, [Val Loss]: 0.07063868641853333\n",
      "tensor(0.9780, device='cuda:0')\n",
      "tensor(0.9782, device='cuda:0')\n",
      "[epoch]: 11, [Train Loss]: 0.06875777989625931, [Val Loss]: 0.06971276551485062\n",
      "tensor(0.9784, device='cuda:0')\n",
      "tensor(0.9782, device='cuda:0')\n",
      "[epoch]: 12, [Train Loss]: 0.06796598434448242, [Val Loss]: 0.06927912682294846\n",
      "tensor(0.9785, device='cuda:0')\n",
      "tensor(0.9784, device='cuda:0')\n",
      "[epoch]: 13, [Train Loss]: 0.06753067672252655, [Val Loss]: 0.0688909962773323\n",
      "tensor(0.9788, device='cuda:0')\n",
      "tensor(0.9785, device='cuda:0')\n",
      "[epoch]: 14, [Train Loss]: 0.06712895631790161, [Val Loss]: 0.06838319450616837\n",
      "tensor(0.9793, device='cuda:0')\n",
      "tensor(0.9795, device='cuda:0')\n",
      "[epoch]: 15, [Train Loss]: 0.06662250310182571, [Val Loss]: 0.0681820660829544\n",
      "tensor(0.9797, device='cuda:0')\n",
      "tensor(0.9797, device='cuda:0')\n",
      "[epoch]: 16, [Train Loss]: 0.06629982590675354, [Val Loss]: 0.06782908737659454\n",
      "tensor(0.9800, device='cuda:0')\n",
      "tensor(0.9797, device='cuda:0')\n",
      "[epoch]: 17, [Train Loss]: 0.06605128943920135, [Val Loss]: 0.06778176128864288\n",
      "tensor(0.9800, device='cuda:0')\n",
      "tensor(0.9797, device='cuda:0')\n",
      "[epoch]: 18, [Train Loss]: 0.06589003652334213, [Val Loss]: 0.06756318360567093\n",
      "tensor(0.9801, device='cuda:0')\n",
      "tensor(0.9798, device='cuda:0')\n",
      "[epoch]: 19, [Train Loss]: 0.06577625870704651, [Val Loss]: 0.06749177724123001\n",
      "tensor(0.9801, device='cuda:0')\n",
      "tensor(0.9798, device='cuda:0')\n",
      "[epoch]: 20, [Train Loss]: 0.06575488299131393, [Val Loss]: 0.06736134737730026\n",
      "tensor(0.9801, device='cuda:0')\n",
      "tensor(0.9798, device='cuda:0')\n",
      "[epoch]: 21, [Train Loss]: 0.0656898021697998, [Val Loss]: 0.06726545095443726\n",
      "tensor(0.9801, device='cuda:0')\n",
      "tensor(0.9799, device='cuda:0')\n",
      "[epoch]: 22, [Train Loss]: 0.0655573382973671, [Val Loss]: 0.06702311336994171\n",
      "tensor(0.9801, device='cuda:0')\n",
      "tensor(0.9797, device='cuda:0')\n",
      "[epoch]: 23, [Train Loss]: 0.06543756276369095, [Val Loss]: 0.06688427180051804\n",
      "tensor(0.9803, device='cuda:0')\n",
      "tensor(0.9800, device='cuda:0')\n",
      "[epoch]: 24, [Train Loss]: 0.06507794559001923, [Val Loss]: 0.06719820201396942\n",
      "tensor(0.9805, device='cuda:0')\n",
      "tensor(0.9801, device='cuda:0')\n",
      "[epoch]: 25, [Train Loss]: 0.06482461839914322, [Val Loss]: 0.06643910706043243\n",
      "tensor(0.9805, device='cuda:0')\n",
      "tensor(0.9799, device='cuda:0')\n",
      "[epoch]: 26, [Train Loss]: 0.06461910158395767, [Val Loss]: 0.06670911610126495\n",
      "tensor(0.9807, device='cuda:0')\n",
      "tensor(0.9802, device='cuda:0')\n",
      "[epoch]: 27, [Train Loss]: 0.06438536942005157, [Val Loss]: 0.06614340841770172\n",
      "tensor(0.9807, device='cuda:0')\n",
      "tensor(0.9802, device='cuda:0')\n",
      "[epoch]: 28, [Train Loss]: 0.06428512185811996, [Val Loss]: 0.06612050533294678\n",
      "tensor(0.9807, device='cuda:0')\n",
      "tensor(0.9803, device='cuda:0')\n",
      "[epoch]: 29, [Train Loss]: 0.06423375755548477, [Val Loss]: 0.06609292328357697\n",
      "tensor(0.9807, device='cuda:0')\n",
      "tensor(0.9803, device='cuda:0')\n",
      "[epoch]: 30, [Train Loss]: 0.06422271579504013, [Val Loss]: 0.06595050543546677\n",
      "tensor(0.9806, device='cuda:0')\n",
      "tensor(0.9801, device='cuda:0')\n",
      "[epoch]: 31, [Train Loss]: 0.06422452628612518, [Val Loss]: 0.06588956713676453\n",
      "tensor(0.9806, device='cuda:0')\n",
      "tensor(0.9802, device='cuda:0')\n",
      "[epoch]: 32, [Train Loss]: 0.0640372708439827, [Val Loss]: 0.06602731347084045\n",
      "tensor(0.9811, device='cuda:0')\n",
      "tensor(0.9811, device='cuda:0')\n",
      "[epoch]: 33, [Train Loss]: 0.06354425847530365, [Val Loss]: 0.06468448787927628\n",
      "tensor(0.9817, device='cuda:0')\n",
      "tensor(0.9812, device='cuda:0')\n",
      "[epoch]: 34, [Train Loss]: 0.06212640181183815, [Val Loss]: 0.06276877224445343\n",
      "tensor(0.9819, device='cuda:0')\n",
      "tensor(0.9814, device='cuda:0')\n",
      "[epoch]: 35, [Train Loss]: 0.060843199491500854, [Val Loss]: 0.06224755570292473\n",
      "tensor(0.9821, device='cuda:0')\n",
      "tensor(0.9816, device='cuda:0')\n",
      "[epoch]: 36, [Train Loss]: 0.06025291234254837, [Val Loss]: 0.06187378242611885\n",
      "tensor(0.9822, device='cuda:0')\n",
      "tensor(0.9817, device='cuda:0')\n",
      "[epoch]: 37, [Train Loss]: 0.05993066355586052, [Val Loss]: 0.061663661152124405\n",
      "tensor(0.9822, device='cuda:0')\n",
      "tensor(0.9817, device='cuda:0')\n",
      "[epoch]: 38, [Train Loss]: 0.0597362294793129, [Val Loss]: 0.061467040330171585\n",
      "tensor(0.9823, device='cuda:0')\n",
      "tensor(0.9819, device='cuda:0')\n",
      "[epoch]: 39, [Train Loss]: 0.059593427926301956, [Val Loss]: 0.06132645159959793\n",
      "tensor(0.9822, device='cuda:0')\n",
      "tensor(0.9816, device='cuda:0')\n",
      "[epoch]: 40, [Train Loss]: 0.05965297296643257, [Val Loss]: 0.06156346574425697\n",
      "tensor(0.9822, device='cuda:0')\n",
      "tensor(0.9816, device='cuda:0')\n",
      "[epoch]: 41, [Train Loss]: 0.059571776539087296, [Val Loss]: 0.06121724098920822\n",
      "tensor(0.9799, device='cuda:0')\n",
      "tensor(0.9788, device='cuda:0')\n",
      "[epoch]: 42, [Train Loss]: 0.06722687929868698, [Val Loss]: 0.068863645195961\n",
      "tensor(0.9789, device='cuda:0')\n",
      "tensor(0.9786, device='cuda:0')\n",
      "[epoch]: 43, [Train Loss]: 0.06521137058734894, [Val Loss]: 0.06503864377737045\n",
      "tensor(0.9811, device='cuda:0')\n",
      "tensor(0.9811, device='cuda:0')\n",
      "[epoch]: 44, [Train Loss]: 0.06288332492113113, [Val Loss]: 0.06382714211940765\n",
      "tensor(0.9817, device='cuda:0')\n",
      "tensor(0.9815, device='cuda:0')\n",
      "[epoch]: 45, [Train Loss]: 0.061918724328279495, [Val Loss]: 0.06320429593324661\n",
      "tensor(0.9819, device='cuda:0')\n",
      "tensor(0.9816, device='cuda:0')\n",
      "[epoch]: 46, [Train Loss]: 0.061236776411533356, [Val Loss]: 0.06269405037164688\n",
      "tensor(0.9821, device='cuda:0')\n",
      "tensor(0.9817, device='cuda:0')\n",
      "[epoch]: 47, [Train Loss]: 0.060807157307863235, [Val Loss]: 0.06264718621969223\n",
      "tensor(0.9821, device='cuda:0')\n",
      "tensor(0.9816, device='cuda:0')\n",
      "[epoch]: 48, [Train Loss]: 0.06058285012841225, [Val Loss]: 0.06228628382086754\n",
      "tensor(0.9822, device='cuda:0')\n",
      "tensor(0.9817, device='cuda:0')\n",
      "[epoch]: 49, [Train Loss]: 0.06037972494959831, [Val Loss]: 0.06209166720509529\n",
      "tensor(0.9821, device='cuda:0')\n",
      "tensor(0.9814, device='cuda:0')\n",
      "[epoch]: 50, [Train Loss]: 0.060373805463314056, [Val Loss]: 0.062401000410318375\n",
      "tensor(0.9822, device='cuda:0')\n",
      "tensor(0.9816, device='cuda:0')\n",
      "[epoch]: 51, [Train Loss]: 0.060268450528383255, [Val Loss]: 0.06206618621945381\n",
      "tensor(0.9821, device='cuda:0')\n",
      "tensor(0.9815, device='cuda:0')\n",
      "[epoch]: 52, [Train Loss]: 0.06016679108142853, [Val Loss]: 0.06188247352838516\n",
      "tensor(0.9822, device='cuda:0')\n",
      "tensor(0.9820, device='cuda:0')\n",
      "[epoch]: 53, [Train Loss]: 0.059936802834272385, [Val Loss]: 0.06120588630437851\n",
      "tensor(0.9824, device='cuda:0')\n",
      "tensor(0.9818, device='cuda:0')\n",
      "[epoch]: 54, [Train Loss]: 0.05956869572401047, [Val Loss]: 0.061466336250305176\n",
      "tensor(0.9825, device='cuda:0')\n",
      "tensor(0.9821, device='cuda:0')\n",
      "[epoch]: 55, [Train Loss]: 0.05915852636098862, [Val Loss]: 0.06066927686333656\n",
      "tensor(0.9826, device='cuda:0')\n",
      "tensor(0.9821, device='cuda:0')\n",
      "[epoch]: 56, [Train Loss]: 0.05883041396737099, [Val Loss]: 0.06051984429359436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9827, device='cuda:0')\n",
      "tensor(0.9821, device='cuda:0')\n",
      "[epoch]: 57, [Train Loss]: 0.058597054332494736, [Val Loss]: 0.06042348966002464\n",
      "tensor(0.9827, device='cuda:0')\n",
      "tensor(0.9823, device='cuda:0')\n",
      "[epoch]: 58, [Train Loss]: 0.05846099555492401, [Val Loss]: 0.06040690094232559\n",
      "tensor(0.9827, device='cuda:0')\n",
      "tensor(0.9822, device='cuda:0')\n",
      "[epoch]: 59, [Train Loss]: 0.05837028846144676, [Val Loss]: 0.06031060963869095\n",
      "tensor(0.9827, device='cuda:0')\n",
      "tensor(0.9820, device='cuda:0')\n",
      "[epoch]: 60, [Train Loss]: 0.058475345373153687, [Val Loss]: 0.06053091958165169\n",
      "tensor(0.9826, device='cuda:0')\n",
      "tensor(0.9823, device='cuda:0')\n",
      "[epoch]: 61, [Train Loss]: 0.05856046453118324, [Val Loss]: 0.06054621934890747\n",
      "tensor(0.9826, device='cuda:0')\n",
      "tensor(0.9821, device='cuda:0')\n",
      "[epoch]: 62, [Train Loss]: 0.05859262868762016, [Val Loss]: 0.06002188101410866\n",
      "tensor(0.9826, device='cuda:0')\n",
      "tensor(0.9823, device='cuda:0')\n",
      "[epoch]: 63, [Train Loss]: 0.05846094340085983, [Val Loss]: 0.060061171650886536\n",
      "tensor(0.9827, device='cuda:0')\n",
      "tensor(0.9821, device='cuda:0')\n",
      "[epoch]: 64, [Train Loss]: 0.058238089084625244, [Val Loss]: 0.05985993519425392\n",
      "tensor(0.9828, device='cuda:0')\n",
      "tensor(0.9823, device='cuda:0')\n",
      "[epoch]: 65, [Train Loss]: 0.05796560272574425, [Val Loss]: 0.05984913930296898\n",
      "tensor(0.9829, device='cuda:0')\n",
      "tensor(0.9822, device='cuda:0')\n",
      "[epoch]: 66, [Train Loss]: 0.05769512429833412, [Val Loss]: 0.0594501718878746\n",
      "tensor(0.9829, device='cuda:0')\n",
      "tensor(0.9824, device='cuda:0')\n",
      "[epoch]: 67, [Train Loss]: 0.05749189108610153, [Val Loss]: 0.05933540686964989\n",
      "tensor(0.9830, device='cuda:0')\n",
      "tensor(0.9824, device='cuda:0')\n",
      "[epoch]: 68, [Train Loss]: 0.057363610714673996, [Val Loss]: 0.05913246423006058\n",
      "tensor(0.9830, device='cuda:0')\n",
      "tensor(0.9822, device='cuda:0')\n",
      "[epoch]: 69, [Train Loss]: 0.057276222854852676, [Val Loss]: 0.05927640199661255\n",
      "tensor(0.9829, device='cuda:0')\n",
      "tensor(0.9825, device='cuda:0')\n",
      "[epoch]: 70, [Train Loss]: 0.05745350569486618, [Val Loss]: 0.05952797085046768\n",
      "tensor(0.9828, device='cuda:0')\n",
      "tensor(0.9821, device='cuda:0')\n",
      "[epoch]: 71, [Train Loss]: 0.057632334530353546, [Val Loss]: 0.05937870591878891\n",
      "tensor(0.9827, device='cuda:0')\n",
      "tensor(0.9823, device='cuda:0')\n",
      "[epoch]: 72, [Train Loss]: 0.05775589495897293, [Val Loss]: 0.05950704589486122\n",
      "tensor(0.9828, device='cuda:0')\n",
      "tensor(0.9820, device='cuda:0')\n",
      "[epoch]: 73, [Train Loss]: 0.057636577636003494, [Val Loss]: 0.05986816808581352\n",
      "tensor(0.9828, device='cuda:0')\n",
      "tensor(0.9821, device='cuda:0')\n",
      "[epoch]: 74, [Train Loss]: 0.057537008076906204, [Val Loss]: 0.059224970638751984\n",
      "tensor(0.9829, device='cuda:0')\n",
      "tensor(0.9826, device='cuda:0')\n",
      "[epoch]: 75, [Train Loss]: 0.05721505731344223, [Val Loss]: 0.058885373175144196\n",
      "tensor(0.9830, device='cuda:0')\n",
      "tensor(0.9825, device='cuda:0')\n",
      "[epoch]: 76, [Train Loss]: 0.056886859238147736, [Val Loss]: 0.05850514769554138\n",
      "tensor(0.9831, device='cuda:0')\n",
      "tensor(0.9825, device='cuda:0')\n",
      "[epoch]: 77, [Train Loss]: 0.056671176105737686, [Val Loss]: 0.0587523877620697\n",
      "tensor(0.9831, device='cuda:0')\n",
      "tensor(0.9825, device='cuda:0')\n",
      "[epoch]: 78, [Train Loss]: 0.05659138038754463, [Val Loss]: 0.05839803069829941\n",
      "tensor(0.9831, device='cuda:0')\n",
      "tensor(0.9825, device='cuda:0')\n",
      "[epoch]: 79, [Train Loss]: 0.05651850998401642, [Val Loss]: 0.05832519382238388\n",
      "tensor(0.9831, device='cuda:0')\n",
      "tensor(0.9824, device='cuda:0')\n",
      "[epoch]: 80, [Train Loss]: 0.05669736489653587, [Val Loss]: 0.05850060284137726\n",
      "tensor(0.9830, device='cuda:0')\n",
      "tensor(0.9826, device='cuda:0')\n",
      "[epoch]: 81, [Train Loss]: 0.05685533583164215, [Val Loss]: 0.0583500899374485\n",
      "tensor(0.9829, device='cuda:0')\n",
      "tensor(0.9825, device='cuda:0')\n",
      "[epoch]: 82, [Train Loss]: 0.056902896612882614, [Val Loss]: 0.05841561779379845\n",
      "tensor(0.9829, device='cuda:0')\n",
      "tensor(0.9826, device='cuda:0')\n",
      "[epoch]: 83, [Train Loss]: 0.056860748678445816, [Val Loss]: 0.05838901549577713\n",
      "tensor(0.9830, device='cuda:0')\n",
      "tensor(0.9826, device='cuda:0')\n",
      "[epoch]: 84, [Train Loss]: 0.05674209073185921, [Val Loss]: 0.058011494576931\n",
      "tensor(0.9831, device='cuda:0')\n",
      "tensor(0.9826, device='cuda:0')\n",
      "[epoch]: 85, [Train Loss]: 0.05641511455178261, [Val Loss]: 0.05798982456326485\n",
      "tensor(0.9832, device='cuda:0')\n",
      "tensor(0.9824, device='cuda:0')\n",
      "[epoch]: 86, [Train Loss]: 0.05612855777144432, [Val Loss]: 0.05811350792646408\n",
      "tensor(0.9832, device='cuda:0')\n",
      "tensor(0.9826, device='cuda:0')\n",
      "[epoch]: 87, [Train Loss]: 0.05592124164104462, [Val Loss]: 0.05773930624127388\n",
      "tensor(0.9832, device='cuda:0')\n",
      "tensor(0.9827, device='cuda:0')\n",
      "[epoch]: 88, [Train Loss]: 0.05582505837082863, [Val Loss]: 0.05812571942806244\n",
      "tensor(0.9833, device='cuda:0')\n",
      "tensor(0.9825, device='cuda:0')\n",
      "[epoch]: 89, [Train Loss]: 0.05576622858643532, [Val Loss]: 0.057851821184158325\n",
      "tensor(0.9832, device='cuda:0')\n",
      "tensor(0.9826, device='cuda:0')\n",
      "[epoch]: 90, [Train Loss]: 0.055947232991456985, [Val Loss]: 0.05770815536379814\n",
      "tensor(0.9831, device='cuda:0')\n",
      "tensor(0.9827, device='cuda:0')\n",
      "[epoch]: 91, [Train Loss]: 0.05613038316369057, [Val Loss]: 0.05750960111618042\n",
      "tensor(0.9831, device='cuda:0')\n",
      "tensor(0.9825, device='cuda:0')\n",
      "[epoch]: 92, [Train Loss]: 0.056198108941316605, [Val Loss]: 0.05787903070449829\n",
      "tensor(0.9831, device='cuda:0')\n",
      "tensor(0.9826, device='cuda:0')\n",
      "[epoch]: 93, [Train Loss]: 0.05613362044095993, [Val Loss]: 0.05758165568113327\n",
      "tensor(0.9831, device='cuda:0')\n",
      "tensor(0.9824, device='cuda:0')\n",
      "[epoch]: 94, [Train Loss]: 0.056070469319820404, [Val Loss]: 0.05786154419183731\n",
      "tensor(0.9832, device='cuda:0')\n",
      "tensor(0.9827, device='cuda:0')\n",
      "[epoch]: 95, [Train Loss]: 0.055700868368148804, [Val Loss]: 0.05779831111431122\n",
      "tensor(0.9833, device='cuda:0')\n",
      "tensor(0.9825, device='cuda:0')\n",
      "[epoch]: 96, [Train Loss]: 0.05537748336791992, [Val Loss]: 0.057209562510252\n",
      "tensor(0.9834, device='cuda:0')\n",
      "tensor(0.9830, device='cuda:0')\n",
      "[epoch]: 97, [Train Loss]: 0.05514274910092354, [Val Loss]: 0.056826379150152206\n",
      "tensor(0.9834, device='cuda:0')\n",
      "tensor(0.9826, device='cuda:0')\n",
      "[epoch]: 98, [Train Loss]: 0.05497882142663002, [Val Loss]: 0.05679452791810036\n",
      "tensor(0.9834, device='cuda:0')\n",
      "tensor(0.9829, device='cuda:0')\n",
      "[epoch]: 99, [Train Loss]: 0.05490221455693245, [Val Loss]: 0.056622233241796494\n"
     ]
    }
   ],
   "source": [
    "trained_model, log = train(0.01, 256, 100, x_train, y_train, x_val, y_val, 10, tgt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = './upvotes/train.csv'\n",
    "# target = 'Upvotes'\n",
    "\n",
    "# X,y = read_and_preprocess_test(file_path, target, tgt_type)\n",
    "ckpt_dir = \"./model_info/14_may_1.pth\"\n",
    "def test(X,y, tgt_type, ckpt_dir):\n",
    "    trained_model = DNN(x_train.shape[1], tgt_type, [128,128,64,32],y_train.shape[1])\n",
    "    trained_model.load_state_dict(torch.load(ckpt_dir))\n",
    "    trained_model\n",
    "    x_test = X\n",
    "    if y is not None:\n",
    "        y_test = y\n",
    "    trained_model.eval()\n",
    "    y_pred = trained_model(x_test)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test(x_val,y_val,tgt_type,ckpt_dir)\n",
    "enc = pickle.load(open('./model_info/OHE.pkl','rb'))\n",
    "df = pd.DataFrame(columns=['gt','predictions'])\n",
    "# df[['predictions']] = scaler_t.inverse_transform(df[['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt = torch.max(y_val, 1)[1].detach().numpy()\n",
    "df = pd.DataFrame(gt)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['gt','predictions'])\n",
    "df['gt'] = gt\n",
    "df['predictions'] = predictions.argmax(dim=1)\n",
    "pred_df = pd.DataFrame(classification_report(df['gt'], df['predictions'], output_dict=True))\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(df['gt'], df['predictions']))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './CICIDS2017/combined_data_test.csv'\n",
    "target = 'Label'\n",
    "x_test, y_test = read_preprocess.read_and_preprocess_test(file_path, target, split)\n",
    "\n",
    "x_test = torch.from_numpy(x_test.to_numpy()).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test(x_test,y_test,tgt_type,ckpt_dir)\n",
    "enc = pickle.load(open('./model_info/OHE.pkl','rb'))\n",
    "df = pd.DataFrame(columns=['gt','predictions'])\n",
    "gt = torch.max(y_test, 1)[1].detach().numpy()\n",
    "df = pd.DataFrame(gt)\n",
    "df = pd.DataFrame(columns=['gt','predictions'])\n",
    "df['gt'] = gt\n",
    "df['predictions'] = predictions.argmax(dim=1)\n",
    "pred_df = pd.DataFrame(classification_report(df['gt'], df['predictions'], output_dict=True))\n",
    "pred_df, pd.DataFrame(confusion_matrix(df['gt'], df['predictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros((gt.size, gt.max()+1))\n",
    "b[np.arange(gt.size),gt] = 1\n",
    "gt2 = b\n",
    "\n",
    "pred = predictions.argmax(dim=1).numpy()\n",
    "b = np.zeros((pred.size,pred.max()+1))\n",
    "b[np.arange(pred.size),pred] = 1\n",
    "pred = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.inverse_transform(gt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gt'] = enc.inverse_transform(gt2)\n",
    "df['predictions'] = enc.inverse_transform(pred)\n",
    "pred_df = pd.DataFrame(classification_report(df['gt'], df['predictions'], output_dict=True))\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['gt'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(df['gt'], df['predictions'],normalize = 'all'), index = labels,columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
